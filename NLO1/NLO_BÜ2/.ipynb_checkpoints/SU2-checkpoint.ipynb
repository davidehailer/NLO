{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programmieraufgaben zur 2. Sonderübung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1\n",
    "In dieser Aufgabe sollen Sie die Performance des Gradientenverfahrens (aus der letzten Sonderübung) mit dem Gauß-Newton Verfahren vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Zielfunktion\n",
    "Implementieren Sie je eine Funktion für den Funktionswert und eine für den Gradienten von NLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_jac(x):\n",
    "    \"\"\"\n",
    "    Jacobian of the inner function\n",
    "    \"\"\"\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return r_jac\n",
    "    \n",
    "def h(x):\n",
    "    \"\"\"\n",
    "    Value of Rosenbrock function\n",
    "    \"\"\"\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return h_val\n",
    "\n",
    "def h_grad(x):\n",
    "    \"\"\"\n",
    "    Gradient of Rosenbrock function\n",
    "    \"\"\"\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return h_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d Plot der Zielfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import cm\n",
    "%matplotlib notebook\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Höhenlinienplot der Zielfunktion\n",
    "Plotten sie mit `plt.contour` die vorgegebenen Höhenlinien der Zielfunktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.hstack((np.arange(0,0.9,0.1),np.arange(1,9,1),np.arange(10,300,20)))\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das Gradientenverfahren\n",
    "Benutzen Sie hierfür die Implementierung aus der 1. Sonderübung (falls Sie nicht teilgenommen haben, ist die Vorlage hier gegeben)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(obj_func, grad_func, line_search, x_0, epsilon):\n",
    "\n",
    "    \"\"\" classical gradient descent\n",
    "    \n",
    "    Input\n",
    "    ----------\n",
    "    obj_fun: callable - Objective function to be mimimized.\n",
    "            Input: ndarray, \n",
    "            Output: float\n",
    "        \n",
    "    grad_fun: callable - Gradient of objective function.\n",
    "            Input: ndarray, \n",
    "            Output: ndarray, \n",
    "    \n",
    "    line_search: callable - Line-search procedure to be used in the algorithm.\n",
    "            Input: x: ndarray\n",
    "                    Starting point of the method.\n",
    "                   d: ndarray\n",
    "                    Starting direction of the method (negative gradient). \n",
    "            Output: float\n",
    "        \n",
    "    x_0: ndarray- Starting point of the method.\n",
    "       \n",
    "    epsilon: float - Tolerance for the termination of the method.\n",
    "        \n",
    "        \n",
    "    Output\n",
    "    -------\n",
    "    x_crit: ndarray - Approx. of a critical point of the objective function.\n",
    "    \n",
    "    f_crit: float - Objective value at x_opt\n",
    "        \n",
    "    k: int - Number of iterations.\n",
    "        \n",
    "    runtime: float - Runtime of the algorithm.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    k = 0\n",
    "    x = x_0\n",
    "    f_grad = ... # Gradienten von f an x auswerten\n",
    "    d = ... # Suchrichtung ergänzen\n",
    "    while ...: # Abbruchkriterium ergänzen\n",
    "        t = ... # Schrittweite bestimmen\n",
    "        x = ... # Update der aktuellen Iterierten\n",
    "        f_grad = ... # Gradient von f an neuer Iterierter\n",
    "        d = ... # Suchrichtung ergänzen\n",
    "        k += 1\n",
    "    x_crit = ... # Approximation eines kritischen Punktes\n",
    "    f_crit = ... # Zielfunktionswert an der Approximation\n",
    "    runtime = ... # Laufzeit des Verfahrens\n",
    "    return x_crit, f_crit, k, runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schrittweitensteuerung\n",
    "Nutzen Sie die in der letzten Sonderübung implementierte Armijo-Regel (falls Sie nicht teilgenommen haben, befindet sich hier eine Vorlage), passen Sie diese gegebenenfalls so an, dass sie sowohl vom Gradientenverfahren, als auch vom Gauß-Newton Verfahren aufgerufen werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def armijo(x, d, obj_func, grad_func, sigma, rho, gamma):\n",
    "    \n",
    "    \"\"\" Armijo stepzise rule\n",
    "    \n",
    "    Parameters\n",
    "    ----------  \n",
    "    x: ndarray - Current iterate of the optimization algorithm.\n",
    "        \n",
    "    d: ndarray - Search direction.\n",
    "    \n",
    "    obj_fun: callable - Objective function to be mimimized. Returns a number.\n",
    "        \n",
    "    grad_fun: callable - Gradient of objective function, returns a vector.\n",
    "       \n",
    "    sigma: float - Parameter that determines flatness of damped tangent. (0<sigma<1)\n",
    "    \n",
    "    rho: float - Parameter that determines how fast stepsize is decreaded. (0<rho<1)\n",
    "        \n",
    "    gamma: float - Parameter that determines appropriate starting stepsize.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    t: float - Armijo stepsize.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    f_value = ... # Funktionswert am Punkt x auswerten\n",
    "    t = ... # Start-Schrittweite (t_0 in Algorithmus 2.4)\n",
    "    x_trial = ... # Schritt in Richtung d mit Schrittweite t\n",
    "    f_trial = ... # Funktionswert am Punkt x_trial\n",
    "    while ...: # Abbruchkriterium ergänzen:\n",
    "        t = ... # Schrittweite updaten\n",
    "        x_trial = ... # Schritt in Richtung d mit neuer Schrittweite t\n",
    "        \n",
    "        f_trial = ... # Funktionswert am neuen Punkt x_trial\n",
    "        \n",
    "    if np.linalg.norm(t*d) < 10**(-14):\n",
    "        t = 10**(-7)\n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das Gauß-Newton-Verfahren\n",
    "Implementieren Sie hier das Gauß-Newton-Verfahren. Orientieren Sie sich hierbei an Algorithmus 2.6 und den Angaben auf S.87 im Buch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussnewton_method(h_val, h_grad, r_jac, x_start, line_search, tol):\n",
    "    \n",
    "    \"\"\" Gauss-Newton-Method\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    h_val: callable - function value of nonlinear least squares problem\n",
    "            Input: x: ndarray\n",
    "            Output h_val: float\n",
    "            \n",
    "    h_grad: callable - gradient of nonlinear least squares problem\n",
    "\n",
    "    r_jac: callable -  Jacobian of inner function\n",
    "        \n",
    "    x_start: ndarray - start iterate of the optimization algorithm.\n",
    "        \n",
    "    line_search: callable - Line-search procedure to be used in the algorithm.\n",
    "    \n",
    "    tol: float -  tolerance parameter for stopping rule\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------- \n",
    "    x_crit: ndarray - Approx. of a critical point of the objective function.\n",
    "    \n",
    "    f_crit: float - Objective value at x_crit\n",
    "        \n",
    "    k: int - Number of iterations.\n",
    "        \n",
    "    runtime: float - Runtime of the algorithm.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return x_crit, f_crit, k, runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausführung beider Verfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst sollte erneut ein Handle für die Armijo-Regel mit der lambda-Notation und die dafür notwendigen Parameter definiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.5\n",
    "rho = 0.4\n",
    "gamma = 1\n",
    "armijo_rule = lambda x, d: armijo(x, d, h, h_grad, sigma, rho, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fügen Sie hier die Implementierung vom Gradientenverfahren aus der letzten Sonderübung ein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Führen Sie nun beide Verfahren mit der Startpunkt $x^0 = (2,5)^\\top$ und der Toleranz $\\varepsilon = 10^{-4}$ aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diskutieren Sie die Ergebnisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2\n",
    "### Hintergrund und Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der in dieser Aufgabe verwendete Datensatz heißt MNIST und stammt von dieser Website: http://yann.lecun.com/exdb/mnist/.\n",
    "\n",
    "Die Datei <b>mnist_data.npz</b> enthält die Matrizen $X\\in\\mathbb{R}^{60000\\times 784}$, $Y\\in\\mathbb{R}^{60000\\times 10}$, $X_t\\in\\mathbb{R}^{10000\\times 784}$ und $Y_t\\in\\mathbb{R}^{10000\\times 10}$. \n",
    "\n",
    "Die Matrizen $X$ und $Y$ enthalten den Datensatz, den Sie in Teilaufgabe a) verwenden sollen. In den Zeilen der Matrix $X$ stehen die Vektoren $x^i$. In den Zeilen von $Y$ sind die zugehörige Vektoren $y^i$ gespeichert. Dieser Datensatz besteht also aus $n=60000$ Datenpunkten.\n",
    "\n",
    "Die Matrizen $X_t\\in\\mathbb{R}^{10000\\times 784}$ und $Y_t\\in\\mathbb{R}^{10000\\times 10}$ enthalten den Test-Datensatz, den Sie in Teilaufgabe b) verwenden sollen. Es gilt ganz analog: In den Zeilen der Matrix $X_t$ stehen die Test-Vektoren $x^i_t$. In den Zeilen von $Y_t$ sind die zugehörige Vektoren $y^i_t$ gespeichert. Der Test-Datensatz besteht also aus $10000$ Datenpunkten.\n",
    "\n",
    "Der Datensatz kann folgendermaßen geladen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"mnist_data.npz\")\n",
    "X = data['X']\n",
    "Y = data['Y']\n",
    "X_t = data['X_t']\n",
    "Y_t = data['Y_t']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die mit den Vektoren $x^i$ kodierten Bilder können sehr einfach visualisiert werden. Wir schauen uns exemplarisch die 111. Zahl an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d56b585820>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "i = 111\n",
    "plot_array = X[i,:].reshape((28,28))\n",
    "matplotlib.pyplot.imshow(plot_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im zugehörigen Vektor $y^i$ ist die Information gespeichert, dass es sich um die Ziffer 3 handelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[i,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Funktionen in MLP.py\n",
    "In der Python-Datei <b>MLP.py</b> finden Sie die Python-Funktionen <b>F</b>, <b>F-gradient</b> und <b>h</b>, welche die Zielfunktion $F$, ihren Gradienten $\\nabla F$ und die Prognosefunktion $h$ implementieren. (Sie müssen diese also nicht selbst implementieren.)\n",
    "\n",
    "Damit Sie die Python-Funktionen in der Datei <b>MLP.py</b> in diesem Jupyter-Notebook verwenden können, importieren wir die Inhalte der Datei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLP import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie: Wir minimieren die Zielfunktion <b>F</b> für einen festen Trainingsdatensatz über die Parameter des neuronalen Netzes. Das heißt, in einem Lösungsverfahren werden <b>F</b> und <b>F-gradient</b> immer für verschiedene Parameter-Vektoren $w\\in \\mathbb{R}^d$ ausgewertet, der Trainingsdatensatz, bestehend aus <b>X</b> und <b>Y</b>, ist fest. \n",
    "\n",
    "Passen Sie daher die Aufrufstruktur mithilfe von lambda-Funktionen an. <b>(1 Punkt)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimierung mit dem Gradientenverfahren "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fügen Sie hier den Code für das Gradientenverfahren mit Armijo-Schrittweitensteuerung erneut ein. Die Parameter $\\sigma$, $\\rho$ und $\\gamma$ können wie zuvor gewählt werden.\n",
    "\n",
    "Beachten Sie, dass in dieser Anwendung die Auswertung des Gradienten und der Zielfunktion recht aufwändig ist. Passen Sie die Methoden daher so an, dass möglichst wenige Auswertungen benötigt werden.\n",
    "\n",
    "Ergänzen Sie ein Zeitlimit, das dem Gradientenverfahren übergeben wird. Die Ausführung der while-Schleife wird beendet, wenn das Zeitlimit überschritten wird. Die Länge des Gradienten von F soll für den Abbruch des Verfahrens keine Rolle spielen. <b>(1 Punkt)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Startpunkte und Aufruf der Methode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Verfahren muss mehrfach mit zufälligen Startpunkten $w^0 \\in \\mathbb{R}^d$ gestartet werden. Für die Vergleichbarkeit der Ergebnisse ist es wichtig, dass alle 3er-Gruppen den Seed des Zufallszahlengenerators auf den gleichen Wert setzen und alle Einträge des Startpunktes aus einer Normalverteilung mit Erwartungswert 0 und Standardabweichung 0.05 ziehen. Erzeugen Sie Ihre Startpunkte deshalb folgendermaßen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0 = np.zeros([10,79510])              # \"Platzhalter\", Startvektoren Nr. i steht in der i-ten Zeile von w_0\n",
    "np.random.seed(123)                     # Setzt den Seed des Zufallszahlengenerators auf 123\n",
    "for k in range(10):                     # 10 Durchläufe\n",
    "    w_0[k,:] = 0.05 * np.random.randn(79510) # Ein neuer \"zufälliger\" Startpunkt für jeden Durchlauf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnen Sie für die 10 zufälligen Startpunkte eine Approximation eines kritischen Punktes der Funktion F mithilfe des zuvor beschriebenen Gradientenverfahrens. Für jeden Startpunkt soll das Verfahren L=240 Sekunden laufen. Geben Sie das arithmetische Mittel und die Standardabweichung der Zielfunktionswerte der berechneten Punkte an. <b>(5 Punkte)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auswertung der Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun sollen Sie die Frage beantworten, wie viel Prozent der Bilder des Test-Datensatzes (<b>$X_t$, $Y_t$</b>) im Mittel korrekt erkannt werden, wenn die Prognosefunktionen verwendet werden, die sich aus den mit dem jeweiligen Verfahren berechneten Punkten ergeben. Was heißt in diesem Kontext \"korrekt erkannt\"? \n",
    "\n",
    "Ein Beispiel: Seien $x\\in\\mathbb{R}^{784}$ ein Punkt des Test-Datensatzes und $y$ das zugehörige Label. Dann sagen wir, dass das Bild $x$ bei Wahl des Punktes/Parameters $w\\in\\mathbb{R}^d$ (aus der vorigen Aufgabe!) korrekt erkannt wird, wenn der Index des größten Eintrags des Vektors $h(x;w)$ mit dem einzigen Nicht-Null-Eintrag von $y$ übereinstimmt, d.h. für $i\\in\\arg\\!\\max h(x;w)$ muss $y_i=1$ gelten.\n",
    "\n",
    "Wenn Sie die Funktion $h$ mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = h(w, X_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aufrufen, enthält die Matrix <b>Y_pred</b> die Vorhersagen für jeden Punkt des Test-Datensatzes bei Wahl des Parameters <b>w</b>. Sie müssen diese Matrix dann wie oben beschrieben mit der gegebenen Matrix <b>Y_t</b> abgleichen, um herauszufinden, wie viel Prozent der Vorhersagen zutreffen. Dies wiederholen Sie dann für jeden der zuvor berechneten Parametervektoren. Berechnen Sie anschließend das arithmetische Mittel und die empirische Standardabweichung der Ergebnisse <b>(4 Punkte)</b>\n",
    "\n",
    "<i> Falls Sie in Teilaufgabe a keine Approximationen für kritische Punkte berechnen konnten, dürfen Sie die Kennzahlen für die zufälligen Startvektoren berechnen </i> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Hinweis zur Abgabe: Laden Sie bitte nicht die Datei `mnist_data.npz` bei der Abgabe wieder mit hoch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
