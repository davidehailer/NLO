{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALL</th>\n",
       "      <th>ALL.1</th>\n",
       "      <th>ALL.2</th>\n",
       "      <th>ALL.3</th>\n",
       "      <th>ALL.4</th>\n",
       "      <th>ALL.5</th>\n",
       "      <th>ALL.6</th>\n",
       "      <th>ALL.7</th>\n",
       "      <th>ALL.8</th>\n",
       "      <th>ALL.9</th>\n",
       "      <th>...</th>\n",
       "      <th>AML.15</th>\n",
       "      <th>AML.16</th>\n",
       "      <th>AML.17</th>\n",
       "      <th>AML.18</th>\n",
       "      <th>AML.19</th>\n",
       "      <th>AML.20</th>\n",
       "      <th>AML.21</th>\n",
       "      <th>AML.22</th>\n",
       "      <th>AML.23</th>\n",
       "      <th>AML.24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.533622</td>\n",
       "      <td>-0.867610</td>\n",
       "      <td>-0.433172</td>\n",
       "      <td>-1.671903</td>\n",
       "      <td>-1.187689</td>\n",
       "      <td>-1.127234</td>\n",
       "      <td>-1.045409</td>\n",
       "      <td>-0.106917</td>\n",
       "      <td>-1.198796</td>\n",
       "      <td>-1.190899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.436650</td>\n",
       "      <td>-1.274708</td>\n",
       "      <td>-0.681458</td>\n",
       "      <td>-0.876610</td>\n",
       "      <td>-0.624022</td>\n",
       "      <td>-0.431628</td>\n",
       "      <td>-1.435259</td>\n",
       "      <td>-0.671954</td>\n",
       "      <td>-1.013161</td>\n",
       "      <td>-0.969482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.235673</td>\n",
       "      <td>-1.275501</td>\n",
       "      <td>-1.184492</td>\n",
       "      <td>-1.596424</td>\n",
       "      <td>-1.335256</td>\n",
       "      <td>-1.113730</td>\n",
       "      <td>-0.800880</td>\n",
       "      <td>-0.745177</td>\n",
       "      <td>-0.849312</td>\n",
       "      <td>-1.190899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.915483</td>\n",
       "      <td>-1.354363</td>\n",
       "      <td>-0.653559</td>\n",
       "      <td>-1.096250</td>\n",
       "      <td>-1.066594</td>\n",
       "      <td>-1.335256</td>\n",
       "      <td>-1.204586</td>\n",
       "      <td>-0.751457</td>\n",
       "      <td>-0.889592</td>\n",
       "      <td>-1.080988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.333983</td>\n",
       "      <td>0.375927</td>\n",
       "      <td>-0.459196</td>\n",
       "      <td>-1.422571</td>\n",
       "      <td>-0.797493</td>\n",
       "      <td>-1.362768</td>\n",
       "      <td>-0.671954</td>\n",
       "      <td>-1.175674</td>\n",
       "      <td>0.320813</td>\n",
       "      <td>0.646610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.736156</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>-0.037455</td>\n",
       "      <td>-0.567335</td>\n",
       "      <td>-1.100749</td>\n",
       "      <td>-0.552938</td>\n",
       "      <td>-0.948874</td>\n",
       "      <td>-0.231657</td>\n",
       "      <td>-0.742163</td>\n",
       "      <td>-0.779500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.488702</td>\n",
       "      <td>0.444011</td>\n",
       "      <td>0.436264</td>\n",
       "      <td>0.193353</td>\n",
       "      <td>0.235632</td>\n",
       "      <td>-0.360312</td>\n",
       "      <td>0.184941</td>\n",
       "      <td>0.425653</td>\n",
       "      <td>0.333983</td>\n",
       "      <td>0.235270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083781</td>\n",
       "      <td>0.356562</td>\n",
       "      <td>0.416241</td>\n",
       "      <td>0.533986</td>\n",
       "      <td>0.227505</td>\n",
       "      <td>0.416816</td>\n",
       "      <td>0.408202</td>\n",
       "      <td>0.326556</td>\n",
       "      <td>0.361813</td>\n",
       "      <td>0.298864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.300893</td>\n",
       "      <td>-1.229660</td>\n",
       "      <td>-1.325882</td>\n",
       "      <td>-1.818329</td>\n",
       "      <td>-1.311206</td>\n",
       "      <td>-1.513975</td>\n",
       "      <td>-1.651624</td>\n",
       "      <td>-1.339555</td>\n",
       "      <td>-0.593132</td>\n",
       "      <td>0.133302</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.547444</td>\n",
       "      <td>-1.264475</td>\n",
       "      <td>-1.512318</td>\n",
       "      <td>-1.469583</td>\n",
       "      <td>-1.283472</td>\n",
       "      <td>-0.977672</td>\n",
       "      <td>-1.090178</td>\n",
       "      <td>-1.545120</td>\n",
       "      <td>-1.174272</td>\n",
       "      <td>-1.443183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7123</th>\n",
       "      <td>1.295992</td>\n",
       "      <td>-0.218494</td>\n",
       "      <td>1.132893</td>\n",
       "      <td>1.113077</td>\n",
       "      <td>0.719203</td>\n",
       "      <td>1.490610</td>\n",
       "      <td>0.483163</td>\n",
       "      <td>1.433292</td>\n",
       "      <td>0.737309</td>\n",
       "      <td>0.633018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.097533</td>\n",
       "      <td>1.154533</td>\n",
       "      <td>1.401608</td>\n",
       "      <td>1.442685</td>\n",
       "      <td>1.097212</td>\n",
       "      <td>0.616776</td>\n",
       "      <td>0.904313</td>\n",
       "      <td>0.861478</td>\n",
       "      <td>1.183783</td>\n",
       "      <td>1.500833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7124</th>\n",
       "      <td>0.733853</td>\n",
       "      <td>0.378380</td>\n",
       "      <td>0.475669</td>\n",
       "      <td>0.148928</td>\n",
       "      <td>0.419502</td>\n",
       "      <td>1.000031</td>\n",
       "      <td>0.258833</td>\n",
       "      <td>-0.498831</td>\n",
       "      <td>-0.657700</td>\n",
       "      <td>-0.373663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496841</td>\n",
       "      <td>0.390495</td>\n",
       "      <td>0.379136</td>\n",
       "      <td>0.833781</td>\n",
       "      <td>0.298680</td>\n",
       "      <td>-0.161740</td>\n",
       "      <td>0.254654</td>\n",
       "      <td>0.558272</td>\n",
       "      <td>0.290234</td>\n",
       "      <td>0.159425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7125</th>\n",
       "      <td>-0.301622</td>\n",
       "      <td>-0.663166</td>\n",
       "      <td>-0.530138</td>\n",
       "      <td>-0.625945</td>\n",
       "      <td>-0.487514</td>\n",
       "      <td>-0.172972</td>\n",
       "      <td>-0.052590</td>\n",
       "      <td>-0.512817</td>\n",
       "      <td>-1.005845</td>\n",
       "      <td>-1.245923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340496</td>\n",
       "      <td>-0.419886</td>\n",
       "      <td>-0.502218</td>\n",
       "      <td>-0.455682</td>\n",
       "      <td>-0.480793</td>\n",
       "      <td>-0.518640</td>\n",
       "      <td>-0.603435</td>\n",
       "      <td>-0.637751</td>\n",
       "      <td>-0.395623</td>\n",
       "      <td>-0.584142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>0.133657</td>\n",
       "      <td>-0.663166</td>\n",
       "      <td>1.566946</td>\n",
       "      <td>0.871972</td>\n",
       "      <td>0.358999</td>\n",
       "      <td>0.080430</td>\n",
       "      <td>0.029891</td>\n",
       "      <td>1.553879</td>\n",
       "      <td>-0.144841</td>\n",
       "      <td>0.129578</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586444</td>\n",
       "      <td>0.216334</td>\n",
       "      <td>1.708574</td>\n",
       "      <td>1.710849</td>\n",
       "      <td>0.844280</td>\n",
       "      <td>1.771676</td>\n",
       "      <td>0.503216</td>\n",
       "      <td>0.079548</td>\n",
       "      <td>0.311388</td>\n",
       "      <td>0.793874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7127</th>\n",
       "      <td>-0.825596</td>\n",
       "      <td>-0.611045</td>\n",
       "      <td>-0.805978</td>\n",
       "      <td>-1.037246</td>\n",
       "      <td>-0.742858</td>\n",
       "      <td>-0.670192</td>\n",
       "      <td>-0.758939</td>\n",
       "      <td>-0.959684</td>\n",
       "      <td>-1.044802</td>\n",
       "      <td>-1.204950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779262</td>\n",
       "      <td>-0.428349</td>\n",
       "      <td>-0.714884</td>\n",
       "      <td>-0.562798</td>\n",
       "      <td>-0.825843</td>\n",
       "      <td>-0.591665</td>\n",
       "      <td>-0.704030</td>\n",
       "      <td>-0.671954</td>\n",
       "      <td>-0.585602</td>\n",
       "      <td>-0.581017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7128 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ALL     ALL.1     ALL.2     ALL.3     ALL.4     ALL.5     ALL.6  \\\n",
       "0    -1.533622 -0.867610 -0.433172 -1.671903 -1.187689 -1.127234 -1.045409   \n",
       "1    -1.235673 -1.275501 -1.184492 -1.596424 -1.335256 -1.113730 -0.800880   \n",
       "2    -0.333983  0.375927 -0.459196 -1.422571 -0.797493 -1.362768 -0.671954   \n",
       "3     0.488702  0.444011  0.436264  0.193353  0.235632 -0.360312  0.184941   \n",
       "4    -1.300893 -1.229660 -1.325882 -1.818329 -1.311206 -1.513975 -1.651624   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7123  1.295992 -0.218494  1.132893  1.113077  0.719203  1.490610  0.483163   \n",
       "7124  0.733853  0.378380  0.475669  0.148928  0.419502  1.000031  0.258833   \n",
       "7125 -0.301622 -0.663166 -0.530138 -0.625945 -0.487514 -0.172972 -0.052590   \n",
       "7126  0.133657 -0.663166  1.566946  0.871972  0.358999  0.080430  0.029891   \n",
       "7127 -0.825596 -0.611045 -0.805978 -1.037246 -0.742858 -0.670192 -0.758939   \n",
       "\n",
       "         ALL.7     ALL.8     ALL.9  ...    AML.15    AML.16    AML.17  \\\n",
       "0    -0.106917 -1.198796 -1.190899  ... -0.436650 -1.274708 -0.681458   \n",
       "1    -0.745177 -0.849312 -1.190899  ... -0.915483 -1.354363 -0.653559   \n",
       "2    -1.175674  0.320813  0.646610  ... -0.736156 -0.022153 -0.037455   \n",
       "3     0.425653  0.333983  0.235270  ...  0.083781  0.356562  0.416241   \n",
       "4    -1.339555 -0.593132  0.133302  ... -1.547444 -1.264475 -1.512318   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7123  1.433292  0.737309  0.633018  ...  1.097533  1.154533  1.401608   \n",
       "7124 -0.498831 -0.657700 -0.373663  ...  0.496841  0.390495  0.379136   \n",
       "7125 -0.512817 -1.005845 -1.245923  ... -0.340496 -0.419886 -0.502218   \n",
       "7126  1.553879 -0.144841  0.129578  ...  1.586444  0.216334  1.708574   \n",
       "7127 -0.959684 -1.044802 -1.204950  ... -0.779262 -0.428349 -0.714884   \n",
       "\n",
       "        AML.18    AML.19    AML.20    AML.21    AML.22    AML.23    AML.24  \n",
       "0    -0.876610 -0.624022 -0.431628 -1.435259 -0.671954 -1.013161 -0.969482  \n",
       "1    -1.096250 -1.066594 -1.335256 -1.204586 -0.751457 -0.889592 -1.080988  \n",
       "2    -0.567335 -1.100749 -0.552938 -0.948874 -0.231657 -0.742163 -0.779500  \n",
       "3     0.533986  0.227505  0.416816  0.408202  0.326556  0.361813  0.298864  \n",
       "4    -1.469583 -1.283472 -0.977672 -1.090178 -1.545120 -1.174272 -1.443183  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7123  1.442685  1.097212  0.616776  0.904313  0.861478  1.183783  1.500833  \n",
       "7124  0.833781  0.298680 -0.161740  0.254654  0.558272  0.290234  0.159425  \n",
       "7125 -0.455682 -0.480793 -0.518640 -0.603435 -0.637751 -0.395623 -0.584142  \n",
       "7126  1.710849  0.844280  1.771676  0.503216  0.079548  0.311388  0.793874  \n",
       "7127 -0.562798 -0.825843 -0.591665 -0.704030 -0.671954 -0.585602 -0.581017  \n",
       "\n",
       "[7128 rows x 72 columns]"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Microarray.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following I will look at the applications of the elastic net with both simulated and real world data.In the simulation part I will simuled data from the true linear model $y = X \\beta + \\epsilon$ with $\\epsilon \\sim N(0,\\sigma)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) Variable Selection:\n",
    "I simulate a training data set of 50(n) observations. Here we set $\\beta = (3,2,7,0,0,0,0,8)^T$ and sigma to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(31)\n",
    "n = 150\n",
    "sigma = 0.5\n",
    "x1 = np.random.normal(0,1,n)\n",
    "x2 = np.random.normal(0,1,n)\n",
    "x3 = np.random.normal(0,1,n)\n",
    "x4 = np.random.normal(0,1,n)\n",
    "x5 = np.random.normal(0,1,n)\n",
    "x6 = np.random.normal(0,1,n)\n",
    "x7 = np.random.normal(0,1,n)\n",
    "x8 = np.random.normal(0,1,n)\n",
    "y = np.random.normal(3*x1 + 2*x2 +7*x3+ 1*x8, sigma,n)\n",
    "X = np.transpose(np.array([x1,x2,x3,x4,x5,x6,x7,x8]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS:\n",
      "[ 3.04158769e+00  2.06608853e+00  6.96948477e+00  1.69008424e-02\n",
      " -4.35105718e-03  7.80175390e-03 -1.69413375e-02  1.00095354e+00]\n",
      "Lasso:\n",
      "[ 3.01914921  2.04554651  6.95279682  0.         -0.          0.\n",
      " -0.          0.97457422]\n",
      "Ridge:\n",
      "[2.82702563e+00 1.95708135e+00 6.35580050e+00 2.58448337e-02\n",
      " 2.74587921e-03 8.40573813e-02 1.99277950e-02 8.74039288e-01]\n",
      "Elastic Net:\n",
      "[ 2.97883096  2.03228098  6.80403957  0.01253205 -0.          0.02248958\n",
      " -0.          0.95848321]\n"
     ]
    }
   ],
   "source": [
    "OLS = LinearRegression().fit(X,y)\n",
    "print(\"OLS:\")\n",
    "print(OLS.coef_)\n",
    "Lasso = LassoCV(normalize = True).fit(X,y)\n",
    "print(\"Lasso:\")\n",
    "print(Lasso.coef_)\n",
    "Ridge = RidgeCV(normalize = True).fit(X,y)\n",
    "print(\"Ridge:\")\n",
    "print(Ridge.coef_)\n",
    "l1ratio = [0.8]\n",
    "ElasticNet = ElasticNetCV(l1_ratio = l1ratio, cv = 10, normalize = True).fit(X,y)\n",
    "print(\"Elastic Net:\")\n",
    "print(ElasticNet.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Elastic Net performs variable selection as it sets several insignificant varibles to exactly zero, but keeps more variables in the model compared to lasso regression due to the grouping effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) Variable Selection\n",
    "To demonstrate the grouping effect we first simulate two variables $Z_1,Z_2 \\sim U(-10,10)$ and then define the predictors in the following way : $(x_1,x_2,x_3,x_4,x_6)^T = (Z_1 + \\epsilon, Z_1 + \\epsilon, Z_2 + \\epsilon, Z_2 + \\epsilon, Z_2 + \\epsilon, -Z_1 + \\epsilon)^T$ with $\\epsilon \\sim N(0,0.001)$ and simulate the dependent variable as $y \\sim N(20\\cdot Z_1 + 0,4 \\cdot Z_2, 10)$. Now we have to groups of variables $x_1,x_2,x_6$ and $x_3, x_4, x_5$ that have a correlation of almost 1 (or -1) within their group and are practically uncorellated between the groups. And the group with $Z_1$ is much more significant and should receive a higher value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(33)\n",
    "n_g = 200\n",
    "sigma = 10\n",
    "Z1 = np.random.uniform(-10,10,n_g)\n",
    "Z2 = np.random.uniform(-10,10,n_g)\n",
    "x_1 = Z1 + np.random.normal(0, 0.01,n_g)\n",
    "x_2 = Z1 + np.random.normal(0, 0.01,n_g)\n",
    "x_3 = Z2 + np.random.normal(0, 0.01,n_g)\n",
    "x_4 = Z2 + np.random.normal(0, 0.01,n_g)\n",
    "x_5 = Z2 + np.random.normal(0, 0.01,n_g)\n",
    "x_6 = -Z1 + np.random.normal(0, 0.01,n_g)\n",
    "y_gr = np.random.normal(20* Z1 + 0.4 * Z2, sigma)\n",
    "X_gr = np.transpose(np.matrix([x_1,x_2,x_3,x_4,x_5,x_6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso:\n",
      "[ 1.99950959e+01  0.00000000e+00  4.86274170e-01  0.00000000e+00\n",
      "  9.23141158e-05 -0.00000000e+00]\n",
      "Elastic Net:\n",
      "[ 4.38119619  4.38085415  0.17553652  0.17574134  0.17592779 -4.38169939]\n"
     ]
    }
   ],
   "source": [
    "Lasso = LassoCV(normalize = True).fit(X_gr,y_gr)\n",
    "print(\"Lasso:\")\n",
    "print(Lasso.coef_)\n",
    "l1ratio = [0.5]\n",
    "ElasticNet = ElasticNetCV(l1_ratio = l1ratio, cv = 10, normalize = True).fit(X_gr,y_gr)\n",
    "print(\"Elastic Net:\")\n",
    "print(ElasticNet.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the elastic net assigns the variables of the same groups a similar value \n",
    "(which demonstrates the grouping effect), were the lasso does not recognize these groups as it assigns them different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.transpose(data.iloc[:,:36])\n",
    "X_test = np.transpose(data.iloc[:,36:])\n",
    "#ALL: 1 / AML = 0\n",
    "y_train = np.array(np.ones(36))\n",
    "y_train[20:34] = 0\n",
    "y_test = np.array(np.ones(36))\n",
    "y_test[25:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-daf488464301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorMat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorMat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorMat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorMat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "corMat = data.corr()\n",
    "sns.heatmap(corMat, xticklabels=corMat.columns, yticklabels=corMat.columns, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificationerror(y_pred,y_true):\n",
    "    for i in range (0,len(y_pred)):\n",
    "        if y_pred[i] >= 0.5:\n",
    "            y_pred[i] = 1\n",
    "        else:\n",
    "            y_pred[i] = 0\n",
    "    return sum(y_pred == y_true)/36\n",
    "def selectedVar(model):\n",
    "    h = sum(model.coef_ == 0)\n",
    "    return (7128 - h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88267182 0.84712323 0.91552316 0.81266586 0.72703817 0.78919289\n",
      " 0.85925449 0.72800925 0.84213499 0.59844043 1.10111452 0.779407\n",
      " 1.09529739 0.97129223 0.69398871 0.74242173 0.95319017 1.20888869\n",
      " 0.92183671 0.78487037 0.82314015 0.93939013 0.80202321 0.96579906\n",
      " 0.76544913 0.22016285 0.37231    0.05673071 0.16546761 0.35578033\n",
      " 0.4080644  0.32634992 0.09786414 0.223033   0.45932975 0.20610437]\n",
      "1.0\n",
      "7128\n"
     ]
    }
   ],
   "source": [
    "OLS_microarray = LinearRegression(normalize = True).fit(X_train,y_train)\n",
    "y_pred1 = OLS_microarray.predict(X_test)\n",
    "print(y_pred1)\n",
    "print(classificationerror(y_pred1,y_test))\n",
    "print(selectedVar(OLS_microarray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722222222222222\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso:\n",
      "0.9166666666666666\n",
      "24\n",
      "Ridge:\n",
      "1.0\n",
      "7128\n",
      "Elastic Net:\n",
      "0.9722222222222222\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "lasso_ma = LassoCV(normalize = True).fit(X_train,y_train)\n",
    "print(\"Lasso:\")\n",
    "y_pred2 = lasso_ma.predict(X_test)\n",
    "print(classificationerror(y_pred2,y_test))\n",
    "print(selectedVar(lasso_ma))\n",
    "\n",
    "###########\n",
    "ridge_ma = RidgeCV(normalize = True).fit(X_train,y_train)\n",
    "print(\"Ridge:\")\n",
    "y_pred3 = ridge_ma.predict(X_test)\n",
    "print(classificationerror(y_pred3,y_test))\n",
    "print(selectedVar(ridge_ma))\n",
    "###########\n",
    "l1ratio = [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]\n",
    "ElasticNet_ma = ElasticNetCV(l1_ratio = l1ratio, cv = 10, normalize = True).fit(X_train,y_train)\n",
    "print(\"Elastic Net:\")\n",
    "y_pred4 = ElasticNet_ma.predict(X_test)\n",
    "print(classificationerror(y_pred4,y_test))\n",
    "print(selectedVar(ElasticNet_ma))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
